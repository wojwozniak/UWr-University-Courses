{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243dfed8",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "Deadline: lab session in the week of **25-28.11.2024**\n",
    "Each task is worth 1 point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3506f4e4",
   "metadata": {},
   "source": [
    "## 1. Maximization of Functions using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5923beff",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Task**:\n",
    "- (a) Maximize the function $f(x) = -x^4 + 4x^2 - 2x + 1$, where $f: \\mathbb{R} \\to \\mathbb{R}$, using gradient ascent. Implement the optimization using PyTorch and plot the convergence over iterations.\n",
    "- (b) Maximize the function $f(x, y, z) = -x^2 - y^2 - z^2 + 2xy - yz + 3z$, where $f: \\mathbb{R}^3 \\to \\mathbb{R}$, using gradient ascent. Implement the optimization using PyTorch and visualize the optimization path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a2ef9",
   "metadata": {},
   "source": [
    "## 2. Linear Regression in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176bfb6",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the following code to generate a synthetic dataset with 100 samples, each with one feature:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "X = np.random.uniform(-10, 10, 100)\n",
    "epsilon = np.random.normal(0, 0.1, 100)\n",
    "y = 3 * X + 4 + epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902863d0",
   "metadata": {},
   "source": [
    "\n",
    "**Task**: Implement a linear regression model using PyTorch to predict the target variable $y$. Train the model to minimize the Mean Squared Error (MSE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb86152",
   "metadata": {},
   "source": [
    "## 3. Learning Rate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e12eb",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the same dataset from Problem 1.\n",
    "\n",
    "**Task**: Modify the `gradient_descent()` function to include different learning rates (0.01, 0.1, 1.0). Visualize the convergence behaviors of gradient descent with each learning rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576b927",
   "metadata": {},
   "source": [
    "## 4. Polynomial Regression Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3d4f5",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the following code to create a dataset of 100 samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0269514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "X = np.random.uniform(-5, 5, 100)\n",
    "epsilon = np.random.normal(0, 0.5, 100)\n",
    "y = 3 * X**3 - 2 * X**2 + 5 + epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd63e11",
   "metadata": {},
   "source": [
    "\n",
    "**Task**: Implement polynomial regression of degree 3 using PyTorch. Train the model and compare the training loss to that of a simple linear regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921634c",
   "metadata": {},
   "source": [
    "## 5. Overfitting and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7e9ce",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the following code to generate a dataset with 150 samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc71c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2)\n",
    "X = np.random.uniform(-10, 10, 150)\n",
    "epsilon = np.random.normal(0, 1, 150)\n",
    "y = 2 * X**2 + 3 * X + 1 + epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76778ca0",
   "metadata": {},
   "source": [
    "\n",
    "**Task**: Fit two models: (i) a linear regression model, and (ii) a polynomial regression model of degree 10. Compare the training and validation performance of both models. Apply L2 regularization to the polynomial model and observe the effect on overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9402be5",
   "metadata": {},
   "source": [
    "## 6. Custom Gradient Descent in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d461107c",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the same dataset from Problem 1.\n",
    "\n",
    "**Task**: Implement a custom gradient descent algorithm without using an optimizer from `torch.optim`. Train a linear regression model using this custom implementation and compare the training results with those obtained using PyTorch's `SGD` optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ca8a2",
   "metadata": {},
   "source": [
    "## 7. Dataset Size and Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9398ff3",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the following code to create three datasets of sizes 50, 100, and 500 samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(3)\n",
    "sizes = [50, 100, 500]\n",
    "datasets = []\n",
    "for size in sizes:\n",
    "    X = np.random.uniform(-10, 10, size)\n",
    "    epsilon = np.random.normal(0, 0.2, size)\n",
    "    y = 4 * X - 3 + epsilon\n",
    "    datasets.append((X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ede6b",
   "metadata": {},
   "source": [
    "\n",
    "**Task**: Train linear regression models on each dataset using PyTorch. Compare the convergence rates of gradient descent for each dataset size by plotting the training loss over epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfa88f",
   "metadata": {},
   "source": [
    "## 8. Effect of Model Complexity on Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d4ddf",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the following code to generate a dataset of 200 samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(4)\n",
    "X = np.random.uniform(-5, 5, 200)\n",
    "epsilon = np.random.normal(0, 0.5, 200)\n",
    "y = 2 * X**2 + X + epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6201f9",
   "metadata": {},
   "source": [
    "\n",
    "**Task**: Fit polynomial regression models of degrees 5 and 15 to the dataset. Plot the training and validation errors for both models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355a493",
   "metadata": {},
   "source": [
    "## 9. Gradient Descent for Non-linear Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8de69f",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset**: Use the following code to generate a dataset of 100 samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(5)\n",
    "X = np.random.uniform(-2 * np.pi, 2 * np.pi, 100)\n",
    "epsilon = np.random.normal(0, 0.1, 100)\n",
    "y = np.sin(X) + epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268103e",
   "metadata": {},
   "source": [
    "\n",
    "**Task**: Implement gradient descent to fit a linear model to this dataset. Discuss the challenges and limitations of fitting a linear model to non-linear data.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
